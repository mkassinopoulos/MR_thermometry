{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of Proteus MR Thermometry\n",
    "```\n",
    "\n",
    "Redistribution and use in source and binary forms, with or without\n",
    "modification, are permitted provided that the following conditions are met:\n",
    "* Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n",
    "* Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n",
    "* Neither the name of the University of Calgary nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n",
    "\n",
    "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\n",
    "ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n",
    "WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "DISCLAIMED. IN NO EVENT SHALL University of Calgary, Samuel Pichardo or an of the contributors BE LIABLE FOR ANY\n",
    "DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n",
    "(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n",
    "LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\n",
    "ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n",
    "(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n",
    "SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "```\n",
    "\n",
    "This notebook illustrates the basic operation to use Proteus MR Thermometry library\n",
    "\n",
    "Be aware some of the underlying structure for the processing is aligned how the main Proteus GUI application organizes the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydicom'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34808/610108136.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mProteus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mThermometryLibrary\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mThermometryLib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mProteus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile_IO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mH5pySimple\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mReadFromH5py\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSaveToH5py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\ThermometryLib\\Proteus\\File_IO\\H5pySimple.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpydicom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muid\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mUID\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pydicom'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from Proteus.ThermometryLibrary import ThermometryLib\n",
    "from Proteus.File_IO.H5pySimple import ReadFromH5py, SaveToH5py\n",
    "import tables\n",
    "import logging \n",
    "from pprint import pprint\n",
    "from Proteus.ThermometryLibrary.ThermometryLib import  LOGGER_NAME\n",
    "\n",
    "from skimage import data, img_as_float\n",
    "from skimage import exposure\n",
    "import warnings\n",
    "\n",
    "logger = logging.getLogger(LOGGER_NAME)\n",
    "\n",
    "stderr_log_handler = logging.StreamHandler()\n",
    "logger.addHandler(stderr_log_handler)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "logger.setLevel(logging.ERROR) #use logging.INFO or logging.DEBUG for detailed step information for thermometry\n",
    "\n",
    "stderr_log_handler.setFormatter(formatter)\n",
    "\n",
    "logger.info(': INITIALIZING MORPHEUS application, powered by Proteus')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and classess required to prepare the MR processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def CompareTwoOrderedLists(list1,list2,bPrintResults=False):\n",
    "    '''\n",
    "    Tool function to evaluate two MRI data collections are equivalent\n",
    "    '''\n",
    "    #please note NavigatorData will be empty, we kept for completeness purposes\n",
    "    [IMAGES2,Navigator2]=list2\n",
    "    [IMAGES,Navigator]=list1\n",
    "    badimagecount = 0\n",
    "    badimages = []\n",
    "    badimageindex = []\n",
    "    \n",
    "    notallsame = False\n",
    "\n",
    "\n",
    "    #Element wise comparison of two sets of results to ensure they match eachother within tolerance\n",
    "    for Stack in IMAGES:\n",
    "        for Map in IMAGES[Stack]:\n",
    "            if Map in ['TimeArrival','SelPointsROI', 'MaskROI' ,'TemperatureROIMask']:\n",
    "                continue\n",
    "            for Number in range(len(IMAGES[Stack][Map])):\n",
    "                for Slice in range(len(IMAGES[Stack][Map][Number])):\n",
    "\n",
    "                    for Data in IMAGES[Stack][Map][Number][Slice]:\n",
    "                        if type(IMAGES[Stack][Map][Number][Slice][Data]) is np.ndarray:\n",
    "                            comparison=np.all(np.isclose(IMAGES[Stack][Map][Number][Slice][Data],\n",
    "                                                  IMAGES2[Stack][Map][Number][Slice][Data]))\n",
    "                            if comparison == False:\n",
    "                                notallsame=True\n",
    "                                if badimageindex.count(Number) == 0:\n",
    "                                    badimagecount += 1\n",
    "                                    badimageindex.append(Number)\n",
    "                                badimages.append((badimagecount,Stack,Map,Number,Slice,Data))\n",
    "                        elif type(IMAGES[Stack][Map][Number][Slice][Data]) is dict:\n",
    "                            for k in IMAGES[Stack][Map][Number][Slice][Data]:\n",
    "                                v1=IMAGES[Stack][Map][Number][Slice][Data][k]\n",
    "                                v2=IMAGES2[Stack][Map][Number][Slice][Data][k]\n",
    "                                if type(v1) is np.ndarray:\n",
    "                                    comparison=np.all(np.isclose(v1,v2))\n",
    "                                else:\n",
    "                                    comparison=v1==v2\n",
    "                                if comparison == False:\n",
    "                                    notallsame=True\n",
    "                                    if badimageindex.count(Number) == 0:\n",
    "                                        badimagecount += 1\n",
    "                                        badimageindex.append(Number)\n",
    "                                    badimages.append((badimagecount,Stack,Map,Number,Slice,Data,k))\n",
    "                        else:\n",
    "                            comparison = (IMAGES[Stack][Map][Number][Slice][Data] == IMAGES2[Stack][Map][Number][Slice][Data])\n",
    "                            if comparison == False:\n",
    "                                notallsame=True\n",
    "                                if badimageindex.count(Number) == 0:\n",
    "                                    badimagecount += 1\n",
    "                                    badimageindex.append(Number)\n",
    "                                badimages.append((badimagecount,Stack,Map,Number,Slice,Data))\n",
    "\n",
    "    \n",
    "\n",
    "    if bPrintResults:\n",
    "        if notallsame == True:\n",
    "            if len(badimages)>0:\n",
    "                print ('The following images did not match within tolerance')\n",
    "                for e in badimages:\n",
    "                    print(e)\n",
    "        else:\n",
    "            print('*'*40+'\\nDatasets were equivalent')\n",
    "    \n",
    "    return notallsame==False        \n",
    "    \n",
    "def CreateSortedDataForProcessing(OBJ):\n",
    "    '''\n",
    "    The two main results to extract for processing are the images and navigator data dictionaries\n",
    "    For thermometry processing , we only need to recover magnitude and phase data\n",
    "    '''\n",
    "    \n",
    "    IMAGES=OBJ['IMAGES']\n",
    "    NavigatorData=OBJ['ExtraData']['NavigatorData']\n",
    "    IMAGES2 = {}\n",
    "    ALL_ITEMS=[]\n",
    "    for k in IMAGES:\n",
    "        #this helps to initializes some empty data structures\n",
    "        IMAGES2[k]={'MaskROI':[None],'SelPointsROI':[None]}\n",
    "        for k2 in {'MaskROI':[None],'SelPointsROI':[None]}:\n",
    "            IMAGES2[k][k2] = IMAGES[k][k2]\n",
    "            \n",
    "    #we reorder the data to mimic how it comes when collecting from a real MRI scanner\n",
    "    for SelKey in IMAGES:\n",
    "        for StackMag,StackPhase in zip(IMAGES[SelKey]['Magnitude'],IMAGES[SelKey]['Phase']):\n",
    "            for ImagMag,ImagPhase in zip(StackMag,StackPhase):\n",
    "                ALL_ITEMS.append(ImagMag)\n",
    "                ALL_ITEMS.append(ImagPhase)\n",
    "    ALL_ITEMS.extend(NavigatorData)\n",
    "    #the data is organized by time of arrival, to emulate how it works during MRI data collection\n",
    "    ORDERED_ITEMS = sorted(ALL_ITEMS, key=lambda k: k['TimeStamp'])\n",
    "    return IMAGES2,ORDERED_ITEMS\n",
    "\n",
    "\n",
    "class InspectMPSData(object):\n",
    "    '''\n",
    "    Minimal class to open MPS files for the re processing\n",
    "    '''\n",
    "    def __init__(self,fname):\n",
    "        print('fname',fname)\n",
    "        self.fname=fname\n",
    "        self.ATables=tables.open_file(fname,'r')\n",
    "        A=self.ATables\n",
    "\n",
    "        NumberTreatments=A.root.Data.MRIONLINE._g_getnchildren()\n",
    "        print(\"Number of treatments \",NumberTreatments)\n",
    "\n",
    "        for treatment in A.root.Data.MRIONLINE._f_list_nodes():\n",
    "             print('   '+treatment._v_name)\n",
    "\n",
    "    def GetDataTreatment(self,iddata):\n",
    "        node=self.ATables.get_node(\"/Data/MRIONLINE/\" +iddata)\n",
    "        print(node)\n",
    "        return ReadOnlineMRIData(node)\n",
    "    \n",
    "class FieldsForImaging:\n",
    "    '''\n",
    "    Class containing attributes defining the parameters controlling the thermometry\n",
    "    \n",
    "    The values can be adjusted to test different parameter conditions\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.Alpha = 9.4e-09  #Thermometry temperature coefficient\n",
    "        self.Beta = 3.0  # Beta Coefficient\n",
    "        self.Gamma = 42580000.0  #Gyromagnetic ratio\n",
    "        self.T_tolerance = 12.0  #SNR limit (*C)\n",
    "        self.CorrectionOrder = 0 #Order of drift correction\n",
    "        self.NumberOfAverageForReference = 4 #number of dynamics for averaging\n",
    "        self.StartReference = 4  #dyn. index ref., thermometry is not calculated in dynamics prior to this #\n",
    "        self.TBaseLine = 37  #Baseline temperature\n",
    "        self.CalculateLargeHistory = True  #Calculate extra history\n",
    "        self.UseUserDriftMask = True # use user-specified ROIs to select mask for drift corrector\n",
    "        self.ROIs ='1 C 4' # string defining ROI mask for monitoring, take a look at \\Proteus\\Tools\\parseROIString.py for details for use\n",
    "        self.UserDriftROIs = '1 R 25 12 0 25' # string defining ROI mask for drift corrector, take a look at \\Proteus\\Tools\\parseROIString.py for details for use\n",
    "        #old mask settings for drift, better to UserDriftROIs instead\n",
    "        self.CircleSizeFORSNRCoronal=45.0\n",
    "        self.RectSizeFORSNRTransverse=110.0\n",
    "        self.MaxSizeSNRRegion=200.0\n",
    "        \n",
    "        self.UseTCoupleForDrift = False #use this if have a setting using thermocouples to minimize excessive drift correction\n",
    "\n",
    "        self.NumberSlicesCoronal = 1  #Number of slices in coronal stack\n",
    "        self.T_mask = 37.0 #Lower limit for temperature mask\n",
    "        \n",
    "        #ECHO NAVIGATOR MOTION COMPENSATOR RELATED parameters\n",
    "        # just kept for completeness as they are now rarely used as we do not have anymore the echonavigator patch\n",
    "        self.UseMotionCompensation = False  #Use Motion Compensation, keep this FALSE unless you have a dataset with echo navigator\n",
    "        self.TimeBeforeFilterNavigator = 10.0  #time before filtering (s)\n",
    "        self.OrderForPredictor = 5  #Order of predictor\n",
    "        self.DiscardedPointsInPredictor = 100  #Tail points to ignore\n",
    "        self.AmplitudeCriteriaForRestMotion = 25.0 # ampl. limit for motion-less detection (%)\n",
    "        self.TimeWindowForClassification = 11  #time window for class. (s)\n",
    "        self.TimeWindowForFiltering = 100  #time window for filter. (s)\n",
    "        self.NumberPointsInterpolateInitialLUT = 100  #Number of points for interpolation fir\n",
    "        self.NumberNavMessagesToWait = 0 #Number of Navigator messages to wait for\n",
    "        self.TimeWindowtoKeepInLUT = 175.0  #'Length of window (s) of entries to keep in LUT'\n",
    "        self.FrequencyCut = 0.8  #Frequency cutoff for butterworth filter (Hz)\n",
    "        \n",
    "\n",
    "#Empty Main object to preserve the structure required by thermometrylib\n",
    "class MainObject: pass\n",
    "\n",
    "class UnitTest:\n",
    "    def __init__(self):\n",
    "        #setting up supporting structures required to perform thermometry\n",
    "        self.ImagingFields=FieldsForImaging()\n",
    "\n",
    "        self.MainObject = MainObject()\n",
    "        self.MainObject.TemporaryData = {}\n",
    "        self.MainObject.TemporaryData['NavigatorDisplacement']=[]\n",
    "        self.MainObject.TemporaryData['FilterForNavigator']=[]\n",
    "        self.MainObject.NavigatorData=[]\n",
    "        self.MainObject.ImagesKeyOrder=['Coronal','Sagittal','User1','User2']\n",
    "        self.MainObject.IMAGES={}\n",
    "        for k in self.MainObject.ImagesKeyOrder:\n",
    "            self.MainObject.IMAGES[k]={'Magnitude':[],'Phase':[],'Temperature':[],'Dose':[],'MaskROI':[None],'SelPointsROI':[None],\n",
    "                                        'TemperatureROIMask':[None]}\n",
    "            self.MainObject.TemporaryData[k]=[]\n",
    "        self.POOL_SIZE=10000\n",
    "        self.POOL_TIME_NAV=np.zeros(self.POOL_SIZE)\n",
    "        self.POOL_DATA_NAV=np.zeros(self.POOL_SIZE)\n",
    "        self.POOL_FILT_DATA_NAV=np.zeros(self.POOL_SIZE)\n",
    "        self.POOL_MOTIONLESS=np.ones(self.POOL_SIZE)*np.nan\n",
    "        self.POOL_INHALATION=np.ones(self.POOL_SIZE)*np.nan\n",
    "        self.POOL_EXHALATION=np.ones(self.POOL_SIZE)*np.nan\n",
    "        self.POOL_FILT_DATA_CLASS=np.zeros(self.POOL_SIZE)\n",
    "        self.POOL_DATA_INDEX=0\n",
    "\n",
    "        self.BackPointsToRefresh=200\n",
    "        self.TotalImages = 0\n",
    "        self.BottomIndexForFiltering=0\n",
    "        self.TProcessor={}\n",
    "        self.InBackground = False\n",
    "        self.cback_UpdateTemperatureProfile = lambda x: None\n",
    "        self.cback_UpdateNavigatorDisplacementProfile = lambda: None\n",
    "        self.cback_UpdateMRIImage = lambda x,y,z: None\n",
    "        self.cback_LockMutex = lambda x: None\n",
    "        self.cback_LockList = lambda x: None\n",
    "        self.IncreaseCounterImageProc = lambda: None\n",
    "        self.MaxSlicesPerDynamicProc =  lambda: 1 #THIS IS ONLUY VALID FOR DATA COLLECTIONS WITH 1 slice per dyanmic\n",
    "        self.GetStackFromSliceNumberFunc =  lambda x: (0,0)\n",
    "        self.NumberSlicesStackFunc = lambda x: 1 #THIS IS ONLUY VALID FOR DATA COLLECTIONS WITH 1 slice per dyanmic\n",
    "        self.ReleaseOnlyNavigatorProc = lambda: None\n",
    "            \n",
    "    \n",
    "    def ReturnElementsToInitializeprocessor(self):\n",
    "        '''\n",
    "        This function prepares a minimal \n",
    "        '''\n",
    "        MO=self.MainObject\n",
    "        return [MO.IMAGES,\n",
    "                MO.TemporaryData,\n",
    "                MO.NavigatorData,\n",
    "                MO.ImagesKeyOrder,\n",
    "                self.IncreaseCounterImageProc,\n",
    "                self.MaxSlicesPerDynamicProc,\n",
    "                self.GetStackFromSliceNumberFunc,\n",
    "                self.NumberSlicesStackFunc,\n",
    "                self.ReleaseOnlyNavigatorProc]\n",
    "            \n",
    "    def BatchProccessor(self, inputdata):\n",
    "        '''\n",
    "        This function reprocess all the magnitude and phase data to recreate a new data collection including thermometry data\n",
    "        '''\n",
    "        #add input data to parent\n",
    "        [IMAGES2,self.MainObject.ORDERED_ITEMS] = CreateSortedDataForProcessing(inputdata)\n",
    "        self.MainObject.MinTime = self.ep.GetReferenceTime()\n",
    "        #process entries one by one\n",
    "        for NewEntry in self.MainObject.ORDERED_ITEMS:\n",
    "\n",
    "            if 'info' in NewEntry:\n",
    "                self.ep.ProcessImage(NewEntry)\n",
    "                self.TotalImages+=1\n",
    "\n",
    "            else:\n",
    "                self.ep.ProcessNavigator(NewEntry)\n",
    "                self.TotalImages+=1\n",
    "\n",
    "        return [self.MainObject.IMAGES,self.MainObject.NavigatorData]\n",
    "    \n",
    "    def BatchProccessorFromList(self, ListInputdata):\n",
    "        '''\n",
    "        This function reprocess all the magnitude and phase data to recreate a new data collection including thermometry data\n",
    "        '''\n",
    "        #add input data to parent\n",
    "        self.MainObject.ORDERED_ITEMS=ListInputdata\n",
    "        self.MainObject.MinTime = 0.0\n",
    "        #process entries one by one\n",
    "        for NewEntry in self.MainObject.ORDERED_ITEMS:\n",
    "\n",
    "            if 'info' in NewEntry:\n",
    "                self.ep.ProcessImage(NewEntry)\n",
    "                self.TotalImages+=1\n",
    "\n",
    "            else:\n",
    "                self.ep.ProcessNavigator(NewEntry)\n",
    "                self.TotalImages+=1\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function to load DICOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import pydicom as dicom\n",
    "def LoadDICOMGe(DCMDir='./',NumberSlicesCoronal =1,ManualTimeBetweenImages=5.0):\n",
    "    '''\n",
    "    Function to load an MR dataset from GE Scanner.\n",
    "\n",
    "    '''\n",
    "\n",
    "    AllFiles=glob.glob(DCMDir+os.sep+'*.dcm')\n",
    "    AllFiles.sort()\n",
    "    NumberFiles=len(AllFiles)\n",
    "\n",
    "    #if must be mutliple of number of dynamics x 2 (real,imag)\n",
    "    if NumberFiles%3 !=0:\n",
    "        raise ValueError('The number of images must be a multiple of 3')\n",
    "\n",
    "    #we'll scan and store all the images and verify how many stacks are in function of the different image orientation\n",
    "\n",
    "    \n",
    "    MatPosOrientation=np.zeros((4,4))\n",
    "    MatPosOrientation[3,3]=1\n",
    "\n",
    "    AllImag=[]\n",
    "    am=None\n",
    "    ar=None\n",
    "    ai=None\n",
    "    pPos = None\n",
    "    nDynamic=1\n",
    "    PreSort=[]\n",
    "    for n in range(NumberFiles):\n",
    "        fdcm = dicom.read_file(AllFiles[n])\n",
    "        PreSort.append(fdcm)\n",
    "        \n",
    "    \n",
    "    warnings.warn('The DICOMS are missing TriggerTime in their Metadata, \\n so there is no automatic way to recover the timing ')\n",
    "    #PreSort.sort(key=lambda fdcm: float(fdcm.TriggerTime))\n",
    "\n",
    "    #print(PreSort)\n",
    "\n",
    "    for fdcm in PreSort:\n",
    "        if fdcm[0x0043, 0x102f].value==0:\n",
    "            if am is not None:\n",
    "                raise ValueError('There should not be preloaded magnitude')\n",
    "            am = fdcm\n",
    "        elif fdcm[0x0043, 0x102f].value==2:\n",
    "            if ar is not None:\n",
    "                raise ValueError('There should not be preloaded real')\n",
    "            ar = fdcm\n",
    "        elif fdcm[0x0043, 0x102f].value==3:\n",
    "            if ai is not None:\n",
    "                raise ValueError('There should not be preloaded imag')\n",
    "            ai = fdcm\n",
    "        else:\n",
    "            raise ValueError('unhandled image type'  +str(fdcm))\n",
    "\n",
    "        if am is None or ai is None or ar is None:\n",
    "            continue\n",
    "        im = am\n",
    "        if pPos is not None:\n",
    "            if pPos==im.ImagePositionPatient:\n",
    "                nDynamic+=1\n",
    "        for m in range(2):\n",
    "            entry={}\n",
    "            entry['TimeStamp']=nDynamic*ManualTimeBetweenImages\n",
    "            #float(im.TriggerTime)/1000.0\n",
    "            Sl={}\n",
    "            if m==0:\n",
    "                imdata=(im.pixel_array).astype(np.float32)\n",
    "            else:\n",
    "                cdata= (ar.pixel_array).astype(np.float32)+\\\n",
    "                        (ai.pixel_array).astype(np.float32) *1j\n",
    "                imdata=-np.angle(cdata) # surface coil\n",
    "                #imdata=np.angle(cdata) #Body coil\n",
    "\n",
    "            Sl['VoxelSize']=np.zeros(3)\n",
    "            Sl['VoxelSize'][0:2]=np.array(im.PixelSpacing)/1e3\n",
    "            Sl['VoxelSize'][2]=float(im.SliceThickness)/1e3\n",
    "            Sl['DynamicLevel']=nDynamic\n",
    "            Sl['EchoTime']=float(im.EchoTime)/1e3\n",
    "            Sl['DynamicAcquisitionTime']=entry['TimeStamp']\n",
    "            Sl['ImageOrientationPatient']=np.array(im.ImageOrientationPatient)\n",
    "            Sl['ImagePositionPatient']=np.array(im.ImagePositionPatient)\n",
    "\n",
    "            ImagePositionPatient=np.array(im.ImagePositionPatient)\n",
    "            ImageOrientationPatient=np.array(im.ImageOrientationPatient)\n",
    "            VoxelSize=np.array(im.PixelSpacing)\n",
    "            MatPosOrientation=np.zeros((4,4))\n",
    "            MatPosOrientation[3,3]=1\n",
    "            MatPosOrientation[0:3,0]=ImageOrientationPatient[0:3]*VoxelSize[0]\n",
    "            MatPosOrientation[0:3,1]=ImageOrientationPatient[3:]*VoxelSize[1]\n",
    "            MatPosOrientation[0:3,3]=ImagePositionPatient\n",
    "\n",
    "            CenterRow=im.Rows/2\n",
    "            CenterCol=im.Columns/2\n",
    "            IndCol=np.zeros((4,1))\n",
    "            IndCol[0,0]=CenterRow\n",
    "            IndCol[1,0]=CenterCol\n",
    "            IndCol[2,0]=0\n",
    "            IndCol[3,0]=1\n",
    "\n",
    "            CenterImagePosition=np.dot(MatPosOrientation,IndCol)\n",
    "\n",
    "            Sl['OffcentreAnteriorPosterior']=CenterImagePosition[1,0]\n",
    "            Sl['OffcentreFeetHead']=CenterImagePosition[2,0]\n",
    "            Sl['OffcentreRightLeft']=CenterImagePosition[0,0]\n",
    "\n",
    "            Sl['RescaleSlope']=1.0\n",
    "            Sl['RescaleIntercept']=0.0\n",
    "            Sl['ScaleSlope']=1.0\n",
    "            Sl['ScaleIntercept']=0.0\n",
    "            Sl['SlicePrepulseDelay']=0\n",
    "            Sl['IsPhaseImage']=(m!=0)\n",
    "            NewEntry={'TimeStamp':entry['TimeStamp'],'info':Sl,'data':imdata}\n",
    "            AllImag.append(NewEntry)\n",
    "        am=None\n",
    "        ar=None\n",
    "        ai=None\n",
    "        if pPos is None:\n",
    "            pPos=im.ImagePositionPatient\n",
    "\n",
    "\n",
    "    #we recreated a pseudo-arrival by ordering the images by timestamp and by type (mag or phase)\n",
    "    SortedImag=sorted(AllImag, key=lambda d: (d['TimeStamp'],d['info']['IsPhaseImage']))\n",
    "\n",
    "\n",
    "    ListOfStacks=[]\n",
    "    FinalList=[]\n",
    "    for entry in SortedImag:\n",
    "        Sl=entry['info']['ImageOrientationPatient'].tolist()+entry['info']['ImagePositionPatient'].tolist()\n",
    "        if Sl not in ListOfStacks:\n",
    "            ListOfStacks.append(Sl)\n",
    "    for entry in SortedImag:\n",
    "        Sl=entry['info']['ImageOrientationPatient'].tolist()+entry['info']['ImagePositionPatient'].tolist()\n",
    "        entry['info']['SliceNumber']=ListOfStacks.index(Sl)\n",
    "        FinalList.append(entry)\n",
    "    return FinalList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ListDataExample=LoadDICOMGe('MR_Thermometry_Examples\\ExampleC\\All',ManualTimeBetweenImages=4.0)\n",
    "print('Total number of images (both magnitude and phase) =',len(ListDataExample))\n",
    "print('Basic Metatada')\n",
    "pprint(ListDataExample[0]['info'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "We use the UnitTest class for demonstration to reprocess MRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ut = UnitTest() #Instantiate a parent class\n",
    "ut.ep = ThermometryLib.EntryProcessing(*ut.ReturnElementsToInitializeprocessor()) #Instantiate an entry processor member on the parent class\n",
    "ut.ep.ImagingFields = ut.ImagingFields #Instantiate a class full of image processing parameters\n",
    "ut.ep.ImagingFields.Beta=1.5\n",
    "ut.ep.ImagingFields.ROIs='1 C 5 -8.2 -3.15'\n",
    "ut.ep.ImagingFields.UserDriftROIs='-1 R 70 25 -8.2 -3.15'\n",
    "ut.ep.ImagingFields.UseUserDriftMask = True\n",
    "ut.ep.ImagingFields.T_tolerance =1.5\n",
    "ut.ep.ImagingFields.StartReference =0\n",
    "ut.ep.ImagingFields.NumberOfAverageForReference=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the original parameters for thermometry processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for k in dir(ut.ep.ImagingFields):\n",
    "    if '_' not in k:\n",
    "        print(k,getattr(ut.ep.ImagingFields,k))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We process the magntiude and phase data. We also use the CompareTwoOrderedLists to show that the repreocess thermometry is the same as in the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ut.BatchProccessorFromList(ListDataExample) #Parent class must posses a method directing the processing of entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can plot the different imaging data (magnitude, phase, thermal and supportive mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xlim1 = 0\n",
    "xlim2 = 255\n",
    "ylim1 = 0\n",
    "ylim2 = 255\n",
    "Main=ut.MainObject\n",
    "\n",
    "def PlotImages(nDynamic, Main,gtitle):\n",
    "    IMAGES=Main.IMAGES\n",
    "    plt.figure(figsize=(18,10))\n",
    "    plt.subplot(2,3,1)\n",
    "    p2, p98 = np.percentile(IMAGES['Coronal']['Magnitude'][nDynamic][0]['data'], (2, 98))\n",
    "    img_rescale = exposure.rescale_intensity(IMAGES['Coronal']['Magnitude'][nDynamic][0]['data'], in_range=(p2, p98))\n",
    "    plt.imshow(img_rescale,cmap=plt.cm.gray)\n",
    "    plt.title('Magnitude')\n",
    "    plt.subplot(2,3,2)\n",
    "    plt.imshow(IMAGES['Coronal']['Phase'][nDynamic][0]['data'],cmap=plt.cm.gray)\n",
    "    plt.title('Phase')\n",
    "    plt.subplot(2,3,3)\n",
    "    plt.imshow(IMAGES['Coronal']['Temperature'][nDynamic][0]['data'],vmin=40,vmax=55,cmap=plt.cm.jet)\n",
    "    #plt.imshow(IMAGES['Coronal']['Temperature'][nDynamic][0]['data'],vmin=40,vmax=55,cmap=plt.cm.jet)\n",
    "    #plt.xlim(0,255)\n",
    "    #plt.ylim(255,0)\n",
    "    plt.xlim(xlim1,xlim2)\n",
    "    plt.ylim(ylim2,ylim1)\n",
    "    plt.colorbar()\n",
    "    plt.title('Temperature map')\n",
    "    \n",
    "    plt.subplot(2,3,4)\n",
    "    plt.imshow(IMAGES['Coronal']['Temperature'][nDynamic][0]['SNR_Mask'],cmap=plt.cm.gray)\n",
    "    plt.title('SNR mask')\n",
    "    plt.subplot(2,3,5)\n",
    "    plt.imshow(IMAGES['Coronal']['Temperature'][nDynamic][0]['SNR_ColdMask'],cmap=plt.cm.gray)\n",
    "    plt.title('\"cold\" SNR mask used for drift correction')\n",
    "    plt.subplot(2,3,6)\n",
    "    #note that the mask for ROI monitoring is constant accross all image and it is stored in the TemporaryData\n",
    "    plt.imshow(Main.TemporaryData['Coronal'][0]['MaskAverage']*1.0,cmap=plt.cm.gray)\n",
    "    plt.title('Mask used for monitoring')\n",
    "    #plt.xlim(0,255)\n",
    "    #plt.ylim(255,0)\n",
    "    plt.xlim(xlim1,xlim2)\n",
    "    plt.ylim(ylim2,ylim1)\n",
    "    plt.colorbar()\n",
    "    plt.suptitle(gtitle)\n",
    "    \n",
    "#PlotImages(0,Main,'Dynamic=0')#\n",
    "#PlotImages(1,Main,'Dynamic=1')#\n",
    "#PlotImages(2,Main,'Dynamic=2')#\n",
    "#PlotImages(3,Main,'Dynamic=3')#\n",
    "#PlotImages(4,Main,'Dynamic=4')#\n",
    "#PlotImages(5,Main,'Dynamic=5')# \n",
    "PlotImages(6,Main,'Dynamic=6')#  \n",
    "#PlotImages(7,Main,'Dynamic=7')#\n",
    "#PlotImages(8,Main,'Dynamic=8')#\n",
    "#PlotImages(9,Main,'Dynamic=9')#\n",
    "PlotImages(10,Main,'Dynamic=10')#\n",
    "#PlotImages(11,Main,'Dynamic=11')#\n",
    "#PlotImages(12,Main,'Dynamic=12')#\n",
    "#PlotImages(13,Main,'Dynamic=13')#\n",
    "#PlotImages(14,Main,'Dynamic=14')#\n",
    "#PlotImages(15,Main,'Dynamic=15')#\n",
    "#PlotImages(16,Main,'Dynamic=16')#\n",
    "#PlotImages(17,Main,'Dynamic=17')#\n",
    "#PlotImages(18,Main,'Dynamic=18')#\n",
    "#PlotImages(19,Main,'Dynamic=19')#\n",
    "#PlotImages(20,Main,'Dynamic=20')#\n",
    "\n",
    "\n",
    "\n",
    "def PlottempImages(Main):\n",
    "    IMAGES=Main.IMAGES\n",
    "    #subinum = 1\n",
    "    #plt.figure(figsize=(35,35))\n",
    "    for i in range(len(IMAGES['Coronal']['Temperature'])):\n",
    "        subi = i\n",
    "        itteration_num = i +1\n",
    "        if ((subi %6) == 0 ):\n",
    "            plt.figure(figsize=(18,10))\n",
    "            subinum = 1\n",
    "        plt.subplot(2,3,subinum)\n",
    "        plt.imshow(IMAGES['Coronal']['Temperature'][i][0]['data'],vmin=40,vmax=60,cmap=plt.cm.jet)\n",
    "        #plt.xlim(0,255)\n",
    "        #plt.ylim(255,0)\n",
    "        plt.xlim(xlim1,xlim2)\n",
    "        plt.ylim(ylim2,ylim1)\n",
    "        plt.colorbar()\n",
    "        plt.title(itteration_num)\n",
    "        subinum = subinum + 1\n",
    "        \n",
    "        \n",
    "PlottempImages(Main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Main.TemporaryData` has also the temperature profile over time resulting from the thermometry in the user ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def PlotTemporalData(Main):\n",
    "    timeD=np.array(Main.TemporaryData['Coronal'][0]['TimeTemperature'])\n",
    "    AvgTemp=np.array(Main.TemporaryData['Coronal'][0]['AvgTemperature'])\n",
    "    T10=np.array(Main.TemporaryData['Coronal'][0]['T10'])\n",
    "    T90=np.array(Main.TemporaryData['Coronal'][0]['T90'])\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(timeD,AvgTemp)\n",
    "    plt.plot(timeD,T10)\n",
    "    plt.plot(timeD,T90)\n",
    "    plt.legend(['Avg. Temperature','T10','T90'])\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Temperature (43$^{\\circ}$))')\n",
    "\n",
    "PlotTemporalData(Main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
